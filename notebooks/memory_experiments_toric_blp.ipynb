{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd8c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import stim\n",
    "import sys\n",
    "import itertools\n",
    "import copy\n",
    "from bposd.css import css_code\n",
    "from beliefmatching import BeliefMatching\n",
    "import pymatching\n",
    "sys.path.append('../src/')\n",
    "from QECCircuits import QECCircuit_OneStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "848b1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "hx_dict_2d_read = joblib.load('../data/hx_dict_2d.pkl')\n",
    "hz_dict_2d_read = joblib.load('../data/hz_dict_2d.pkl')\n",
    "hx_dict_3d_read = joblib.load('../data/hx_dict_3d.pkl')\n",
    "hz_dict_3d_read = joblib.load('../data/hz_dict_3d.pkl')\n",
    "toric_hx_dict_2d = joblib.load('../data/toric_hx_dict_2d.pkl')\n",
    "toric_hz_dict_2d = joblib.load('../data/toric_hz_dict_2d.pkl')\n",
    "toric_hx_dict_3d = joblib.load('../data/toric_hx_dict_3d.pkl')\n",
    "toric_hz_dict_3d = joblib.load('../data/toric_hz_dict_3d.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b802e5",
   "metadata": {},
   "source": [
    "# Set up 3D codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce80aa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D code toric: (nan,nan)-[[81,3,3]]\n",
      "3D code BLP: (nan,nan)-[[27,3,3]]\n",
      "3D code toric: (nan,nan)-[[375,3,5]]\n",
      "3D code BLP: (nan,nan)-[[81,3,5]]\n"
     ]
    }
   ],
   "source": [
    "codes_3D = {}\n",
    "\n",
    "for d in [3, 5]:\n",
    "    code_3D = css_code(toric_hx_dict_3d[d], toric_hz_dict_3d[d])\n",
    "    eval_code = code_3D\n",
    "    # commented out because this requires py 3.7 (run it on a separate kernel to confirm)\n",
    "    # num_trials = 200\n",
    "    # dz = DistanceEst_BPOSD(eval_code.hx, eval_code.lx, num_trials) \n",
    "    # dx = DistanceEst_BPOSD(eval_code.hz, eval_code.lz, num_trials)\n",
    "    # eval_code.D = min(dz, dx)\n",
    "    eval_code.D = d\n",
    "    print(\"3D code toric:\", code_3D.code_params)\n",
    "    codes_3D[f'd{d}_toric'] = code_3D\n",
    "\n",
    "    code_3D = css_code(hx_dict_3d_read[d], hz_dict_3d_read[d])\n",
    "    eval_code = code_3D\n",
    "    # dz = DistanceEst_BPOSD(eval_code.hx, eval_code.lx, num_trials)\n",
    "    # dx = DistanceEst_BPOSD(eval_code.hz, eval_code.lz, num_trials)\n",
    "    # eval_code.D = min(dz, dx)\n",
    "    eval_code.D = d\n",
    "    print(\"3D code BLP:\", code_3D.code_params)\n",
    "    codes_3D[f'd{d}_blp'] = code_3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38031436",
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in codes_3D.values():\n",
    "    code.hx = code.hx.toarray()\n",
    "    code.hz = code.hz.toarray()\n",
    "    code.lx = code.lx.toarray()\n",
    "    code.lz = code.lz.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78974bc",
   "metadata": {},
   "source": [
    "# Memory experiment with 3D codes (toric and BLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "188fd2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_error_rates = np.logspace(-3, -2, num=6)\n",
    "circuit_error_params = {\"p_i\": 0, \"p_state_p\": 1, \"p_m\": 1, \"p_CX\":1, \"p_idling_gate\": 0}\n",
    "\n",
    "unnormalized_LFRs_dict = {code_id: [] for code_id in codes_3D.keys()}\n",
    "normalized_LFRs_dict = {code_id: [] for code_id in codes_3D.keys()} # remember to normalize by kd\n",
    "\n",
    "num_samples_dict = {'d3_toric': [2000]*6,\n",
    "                    'd5_toric': [2000]*6,\n",
    "                    'd3_blp': [2000]*6,\n",
    "                    'd5_blp': [2000]*6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a98c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "CODE: d3_blp (nan,nan)-[[27,3,3]]\n",
      "p=0.0010000000 | num shots=2000 | LFR=0.013500 | normalized LFR=0.001509077253793789\n",
      "p=0.0015848932 | num shots=2000 | LFR=0.023500 | normalized LFR=0.0026387932110290002\n",
      "p=0.0025118864 | num shots=2000 | LFR=0.057000 | normalized LFR=0.0064997840170825105\n",
      "p=0.0039810717 | num shots=2000 | LFR=0.140000 | normalized LFR=0.01661846301918468\n",
      "p=0.0063095734 | num shots=2000 | LFR=0.254500 | normalized LFR=0.03210662679430243\n",
      "p=0.0100000000 | num shots=2000 | LFR=0.502500 | normalized LFR=0.07464080921962202\n",
      "--------------------------------\n",
      "CODE: d5_blp (nan,nan)-[[81,3,5]]\n",
      "p=0.0010000000 | num shots=2000 | LFR=0.003000 | normalized LFR=0.00020028054252707594\n",
      "p=0.0015848932 | num shots=2000 | LFR=0.017000 | normalized LFR=0.0011424241917163958\n",
      "p=0.0025118864 | num shots=2000 | LFR=0.064000 | normalized LFR=0.004399613386810053\n",
      "p=0.0039810717 | num shots=2000 | LFR=0.201500 | normalized LFR=0.014889394324754557\n",
      "p=0.0063095734 | num shots=2000 | LFR=0.503500 | normalized LFR=0.04560545104133429\n"
     ]
    }
   ],
   "source": [
    "num_shots_per_batch = 10_000\n",
    "for code_id in ['d3_blp', 'd5_blp', 'd3_toric', 'd5_toric']:\n",
    "    eval_code = codes_3D[code_id]\n",
    "    num_rep = eval_code.D\n",
    "    print(\"--------------------------------\")\n",
    "    print(f\"CODE: {code_id} {eval_code.code_params}\")\n",
    "    for i, p in enumerate(physical_error_rates):\n",
    "        num_shots = num_samples_dict[code_id][i]\n",
    "        circuit = QECCircuit_OneStage(eval_code, num_rep, circuit_error_params, p, merged_scheduling=None)\n",
    "        dem = circuit.detector_error_model(decompose_errors=True)\n",
    "        matcher = pymatching.Matching.from_detector_error_model(dem)\n",
    "        sampler = circuit.compile_detector_sampler()\n",
    "        det_chunks, log_chunks, pred_chunks = [], [], []\n",
    "        num_batches, leftover = num_shots//num_shots_per_batch, num_shots%num_shots_per_batch\n",
    "        total_mistakes = 0\n",
    "        for batch_i in range(num_batches+1):\n",
    "            if batch_i == num_batches:\n",
    "                if leftover == 0:\n",
    "                    break\n",
    "                batch_detector_vals, batch_logical_vals = sampler.sample(leftover, separate_observables=True)\n",
    "            else:\n",
    "                batch_detector_vals, batch_logical_vals = sampler.sample(num_shots_per_batch, separate_observables=True)\n",
    "            batch_pred_vals = matcher.decode_batch(batch_detector_vals)\n",
    "            batch_num_mistakes = np.sum(np.any(batch_pred_vals != batch_logical_vals, axis=1))\n",
    "            \n",
    "            det_chunks.append(batch_detector_vals)\n",
    "            log_chunks.append(batch_logical_vals)\n",
    "            pred_chunks.append(batch_pred_vals)\n",
    "            total_mistakes += batch_num_mistakes\n",
    "        detector_vals = np.concatenate(det_chunks, axis=0)\n",
    "        logical_vals  = np.concatenate(log_chunks,  axis=0)\n",
    "        if len(detector_vals) != num_shots or len(logical_vals) != num_shots:\n",
    "            print(\"incorrect number of shots\")\n",
    "            print(f\"det len {len(detector_vals)} | log len {len(logical_vals)}\")       \n",
    "        LFR = total_mistakes/num_shots\n",
    "        normalized_LFR = 1-(1-LFR)**(1/(eval_code.K * eval_code.D))\n",
    "        print(f\"p={p:.10f} | num shots={num_shots} | LFR={LFR:5f} | normalized LFR={normalized_LFR}\")\n",
    "        unnormalized_LFRs_dict[code_id].append(LFR)\n",
    "        normalized_LFRs_dict[code_id].append(normalized_LFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e442240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with idling, compact\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "printed_code_params = {code_id: f\"{code.code_params}\".split('-')[1] for code_id, code in codes_3D.items()}\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(14.4)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "plt.plot(physical_error_rates, normalized_LFRs_dict['d3_toric'], marker='o', linestyle=':', color='C0', label=f\"toric {printed_code_params['d3_toric']}\", linewidth=3)\n",
    "plt.plot(physical_error_rates, normalized_LFRs_dict['d5_toric'], marker='o', linestyle=':', color='C1', label=f\"toric {printed_code_params['d5_toric']}\", linewidth=3)\n",
    "plt.plot(physical_error_rates, normalized_LFRs_dict['d3_blp'], marker='o', linestyle='-', color='C0', label=f\"blp {printed_code_params['d3_blp']}\", linewidth=3)\n",
    "plt.plot(physical_error_rates, normalized_LFRs_dict['d5_blp'], marker='o', linestyle='-', color='C1', label=f\"blp {printed_code_params['d5_blp']}\", linewidth=3)\n",
    "# plt.plot(physical_error_rates, normalized_LFRs_dict['d3_pentagon'], marker='o', linestyle='--', color='C0', label=f\"pentagon {printed_code_params['d3_pentagon']}\", linewidth=3)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "# plt.ylim(10e-6, 2*10e-2)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Physical Error Rate')\n",
    "plt.ylabel('Normalized Logical Failure Rate')\n",
    "plt.title('Normalized Logical Failure Rate vs Physical Error Rate\\n for Memory Experiment with 3D Codes')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sage 10.5 venv",
   "language": "python",
   "name": "sagevenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
